{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "import pandas as pd\n",
    "from path import Path as path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = path(\"model/\").mkdir_p()\n",
    "enfj = pd.read_csv(\"enfj.csv\", index_col = 0)\n",
    "infp = pd.read_csv(\"infp.csv\", index_col = 0)\n",
    "df = enfj.append(infp)\n",
    "intp = pd.read_csv(\"intp.csv\", index_col = 0)\n",
    "df = df.append(intp)\n",
    "intj = pd.read_csv(\"intj.csv\", index_col = 0)\n",
    "df = df.append(intj)\n",
    "entj = pd.read_csv(\"entj.csv\", index_col = 0)\n",
    "df = df.append(entj)\n",
    "entp = pd.read_csv(\"entp.csv\", index_col = 0)\n",
    "df = df.append(entp)\n",
    "enfp = pd.read_csv(\"enfp.csv\", index_col = 0)\n",
    "df = df.append(enfp)\n",
    "infj = pd.read_csv(\"infj.csv\", index_col = 0)\n",
    "df = df.append(infj)\n",
    "istj = pd.read_csv(\"istj.csv\", index_col = 0)\n",
    "df = df.append(istj)\n",
    "istp = pd.read_csv(\"istp.csv\", index_col = 0)\n",
    "df = df.append(istp)\n",
    "isfj = pd.read_csv(\"isfj.csv\", index_col = 0)\n",
    "df = df.append(isfj)\n",
    "isfp = pd.read_csv(\"isfp.csv\", index_col = 0)\n",
    "df = df.append(isfp)\n",
    "estj = pd.read_csv(\"estj.csv\", index_col = 0)\n",
    "df = df.append(estj)\n",
    "estp = pd.read_csv(\"estp.csv\", index_col = 0)\n",
    "df = df.append(estp)\n",
    "esfj = pd.read_csv(\"esfj.csv\", index_col = 0)\n",
    "df = df.append(esfj)\n",
    "esfp = pd.read_csv(\"esfp.csv\", index_col = 0)\n",
    "df = df.append(esfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df.to_csv(\"model/mbti.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language model data\n",
    "data_lm = TextLMDataBunch.from_csv(path2, 'mbti.csv')\n",
    "# Classifier model data\n",
    "data_clas = TextClasDataBunch.from_csv(path2, 'mbti.csv', vocab=data_lm.train_ds.vocab, bs=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm.save('data_lm_export.pkl')\n",
    "data_clas.save('data_clas_export.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = load_data(path2, 'data_lm_export.pkl')\n",
    "data_clas = load_data(path2, 'data_clas_export.pkl', bs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='5934', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-38496597dee4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlearn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlanguage_model_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_lm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAWD_LSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_mult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     21\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m def get_preds(model:nn.Module, dl:DataLoader, pbar:Optional[PBar]=None, cb_handler:Optional[CallbackHandler]=None,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.5)\n",
    "learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(1, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " learn.save(\"save0\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This is a review about what 's going on in my head that helps very\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict(\"This is a review about\", n_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save_encoder('ft_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)\n",
    "learn.load_encoder('ft_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>xxbos i strongly believe that to understand how each type views the world , you look at the art they make and swear by . \\n  xxmaj you can think of r / mbtiradiostation as a place to broadcast , type and discuss music , podcasts , videos or whatever you are watching . xxmaj the goal is to create a directory but you can discuss anything xxmaj art</td>\n",
       "      <td>entp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj well ! xxmaj this is right up my wheelhouse , so i 'm going to try to give an anecdotal response . xxmaj apologies in advance for how long it is . \\n  xxmaj my most recent ex is an infp . xxmaj although the situation that lead to our breakup had other factors ( some which included my own need to be single , lots of</td>\n",
       "      <td>infj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj you assume a link between mental disorders and the lack of an evolutionary role , i don´t see the reason behind this assumption . xxmaj you made the claim but you did n’t back up that hypothesis and , xxup imo , not even explained the logic behind it . xxmaj the definition of mental disorder is “ a mental disorder , also called a mental xxunk ]</td>\n",
       "      <td>entp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj this sub took a major turn for the worse when it got infiltrated by shills from xxmaj xxunk , xxmaj forever 21 , xxmaj waffle xxmaj house , and the xxup us xxmaj postal xxmaj service . xxmaj not to mention xxmaj blockbuster xxmaj video , which has n't actually died but rather is laying in wait , and in the meantime is doing shit like infiltrate r</td>\n",
       "      <td>infp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos i 'm an xxup isfp and i really really like other people ( mainly celebrities ) that seem to have xxup isfp qualities . xxmaj for example , musicians : i have seen xxmaj lana xxmaj del xxmaj rey , xxmaj marina xxmaj diamandis , and xxmaj lorde all typed as isfps before . xxmaj to me , they also seem like isfps . \\n  xxmaj my favorite</td>\n",
       "      <td>isfp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_clas.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.227494</td>\n",
       "      <td>2.162488</td>\n",
       "      <td>0.273315</td>\n",
       "      <td>39:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.059655</td>\n",
       "      <td>2.717730</td>\n",
       "      <td>0.362135</td>\n",
       "      <td>43:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(1, slice(5e-3/2., 5e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.881046</td>\n",
       "      <td>1.832795</td>\n",
       "      <td>0.414018</td>\n",
       "      <td>1:08:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(1, slice(2e-3/100, 2e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(\"mbti_ulmfit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(\"save1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.7/site-packages/fastai/basic_train.py:327: UserWarning: Wasn't able to properly load the optimizer state again.\n",
      "  except: warn(\"Wasn't able to properly load the optimizer state again.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (183873 items)\n",
       "x: TextList\n",
       "xxbos xxmaj what i 'm seeing is the construction of a number of narratives that get running before you 've actually met anyone . xxmaj as if the ' worst case ' applies to everyone regardless of who they are . \n",
       "  xxmaj do you believe in god ?,xxbos i 'm not sure , \" truth is a mutually agreed upon approximation \" is true . xxmaj there are some truths that are true in the absence of , or even in the antithesis of what is mutually agreed upon . \n",
       "  xxmaj it is true that all knowledge must be funneled through beings of subjectivity . xxmaj but this is why what we know ( or think ) is true , is what empirical evidence is found independently of human subjectivities . xxmaj maybe one can say this is not possible . \n",
       "  xxmaj but consider this example . xxmaj whenever a monumental discovery is made in science , it is often found in the face of a contradictory established belief . xxmaj for instance when xxmaj galileo discovered the moon and other planets are round floating balls in space rotating around the sun , he was able to find this even when the established belief was that the earth was an flat plain , where the sun and stars moved above and across the earth 's flat plain . \n",
       "  xxmaj what do you think about this ? i want to hear your thoughts . i believe that some approximated truths have been so consistent that it 's safe to assume we have some gradient of objective knowledge about said proofs .,xxbos xxmaj oh i know . i started just saying any even partially valid points but then ran out if logical arguments for xxunk and also got too caught up in the debate aspect of it . xxmaj pretty common problem for me , tbh h xxrep 4 m i wonder why 🤔,xxbos i 'm stepping away from paying attention to politics for a few days / weeks after recent announcement about the xxmaj supreme xxmaj court , until i can think about it without the desperation / rage / fear / tears welling up sensation that i feel when i think about things right now . xxmaj sometimes you have to step back for a while when you really care , in order to preserve your xxunk . xxmaj we 're in this for the long haul , and positive things are happening too . xxmaj do n't let the bad stuff take you down with it .,xxbos xxmaj no . xxmaj it automatically comes from neckbeards because it 's typical whiny bollocks that does n't translate into real life . \n",
       "  xxmaj nice gender stereotyping , and heteronormative statements . xxmaj but coming from the guy who has an issue with feminists , i 'm not surprised . \n",
       "  xxmaj is that supposed to insult me ? xxmaj think what you want . i do n't care .\n",
       "y: CategoryList\n",
       "intj,intp,entp,infj,intj\n",
       "Path: model;\n",
       "\n",
       "Valid: LabelList (45969 items)\n",
       "x: TextList\n",
       "xxbos xxmaj yes , i see them every week and i just got my xxmaj real xxmaj estate xxmaj license to work with my xxmaj mexican mum . xxmaj we 're pretty close . \n",
       "  i cooked for my boyfriend on our second date he he lied about liking cilantro . i 've never been properly cheated on but this was the closest thing . xxmaj we 've been working through this for four years .,xxbos xxmaj fellow enfjs ! xxmaj what do you find most frustrating about other types ? \n",
       "  xxmaj for example , i find a lot of non - xxmaj fe people to occasionally be socially unaware and / or inconsiderate . i still love 'em , obviously , but xxup grr . \n",
       "  xxmaj what 's yours ? xxmaj vent !,xxbos xxmaj my grieving process differs for each situation . xxmaj this is my grieving process of my current situation i 'm dealing with now ... \n",
       " \n",
       "  xxmaj shock mode , unable to process what 's going on . xxmaj is this really happening ? xxmaj why am i not crying ? xxmaj probably what you call detachment mode in the beginning . xxmaj ca n't really seem to talk to most people about it except for my best friend . \n",
       "  xxmaj grieving ... xxmaj when the emotions hit hard . xxmaj sometimes crying is involved . \n",
       "  xxmaj unhealthy coping mechanism for example alcohol . \n",
       "  xxmaj acceptance of what happened and then i find every solution or way to repair the situation . xxmaj this is also the time i 'm seeking for answers . xxmaj during this time i am also doing stuff to self improve . \n",
       "  i start feeling better and feel like i 'm healing . \n",
       "  xxmaj but wait , it did n't get fixed correctly so then i 'm dealing with failure now . \n",
       "  xxmaj then denial ... xxmaj is this really going to work or am i just wasting my time fixing something that 's irreparable ? \n",
       "  xxmaj unhealthy coping mechanism with alcohol again to deal with all this . \n",
       "  xxmaj repeat steps 2 - 8 for awhile . \n",
       "  xxmaj then finally reality hits me , got ta accept my truth and move on for good . xxmaj some grieving , support from others , coping mechanism are all involved for me to be able to move on easier . \n",
       " \n",
       "  xxmaj luckily not much anger involved in this situation . xxmaj just a lot of sorrow . i used to self detach from every situation when i was younger , that was my go to number 1 thing to do , but it seemed like i was running away from my problems instead of facing them . xxmaj so for this situation i 'm not using detachment as much .,xxbos xxmaj it has been about 3 years for me to figure out my personality type from the inaccuracies of taking the mbti test multiple times . i am unsure whether my personality is correct but i kept testing to make sure of my results . i got xxup istj many times now . i had kept notes of my results since those years and saw i had xxup enfp before . i 'm 19 which feels young to me to be considered knowledgeable since i know there s a lot to learn even during those past years . \n",
       "  xxmaj well , i was considering whether i am an xxup enfp or xxup istj after i thought maybe i should read the \" xxmaj extrovert \" side descriptions . xxmaj after i did , i felt something familiar . xxmaj it must be because of the functions . xxup istj having xxmaj si - xxmaj te - xxmaj fi - xxmaj ne and xxup enfp having xxmaj ne - xxmaj fi - xxmaj te - xxmaj si , i hope i 'm not mistaken of these functions but i 'm sure it should be right . i had read that both of these personality are more ambivert than some others too so there should be a reason for that . \n",
       "  xxmaj from my experience during my pre - teen years i was very spontaneous but that s with my closest friends ( 2 of them ) and they thought i was weird in a good way . ( i 'd be so comfortable that i 'd be running and jumping ) i can be silly and weird . i only was like this with my church friends mostly , because for school , i wanted to focus on the teacher and listen ( at least tried to ) . i did n't bother much with interacting with other students since i was occupied with my work , but i did like listening to others ' conversations . xxmaj it makes me want to join in too but i just did n't have time for that . xxmaj so i 'm pretty much very focused on my work but i have a fun side to express too . i can get really creative with words , puns and seems like to others its bad / good ? i was asked before \" how did you come up with these ? \" ... xxmaj but it really just comes to my mind . xxmaj like i feel like i 'm constantly thinking and when my mind gets bored or when i find a really good joke , i 'll say it .,xxbos xxmaj do n't waste time on the race to be xxmaj mr or xxmaj miss xxmaj popular . xxmaj friendships is about quality , not quantity . xxmaj do n't succumb to peer pressure to become somebody you 're not , or do \n",
       "  dangerous and illegal things \n",
       "  xxmaj unless it breaks rules , do what makes you happy and enjoy your youth before you become an adult . xxmaj of course , you should try your best to get good grades in school , but set aside time for leisure as well .\n",
       "y: CategoryList\n",
       "intj,enfj,intp,istj,istp\n",
       "Path: model;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(60004, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(60004, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1150, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1150, 1150, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1150, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=16, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fab1dc847b8>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('model'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
       "learn: RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (183873 items)\n",
       "x: TextList\n",
       "xxbos xxmaj what i 'm seeing is the construction of a number of narratives that get running before you 've actually met anyone . xxmaj as if the ' worst case ' applies to everyone regardless of who they are . \n",
       "  xxmaj do you believe in god ?,xxbos i 'm not sure , \" truth is a mutually agreed upon approximation \" is true . xxmaj there are some truths that are true in the absence of , or even in the antithesis of what is mutually agreed upon . \n",
       "  xxmaj it is true that all knowledge must be funneled through beings of subjectivity . xxmaj but this is why what we know ( or think ) is true , is what empirical evidence is found independently of human subjectivities . xxmaj maybe one can say this is not possible . \n",
       "  xxmaj but consider this example . xxmaj whenever a monumental discovery is made in science , it is often found in the face of a contradictory established belief . xxmaj for instance when xxmaj galileo discovered the moon and other planets are round floating balls in space rotating around the sun , he was able to find this even when the established belief was that the earth was an flat plain , where the sun and stars moved above and across the earth 's flat plain . \n",
       "  xxmaj what do you think about this ? i want to hear your thoughts . i believe that some approximated truths have been so consistent that it 's safe to assume we have some gradient of objective knowledge about said proofs .,xxbos xxmaj oh i know . i started just saying any even partially valid points but then ran out if logical arguments for xxunk and also got too caught up in the debate aspect of it . xxmaj pretty common problem for me , tbh h xxrep 4 m i wonder why 🤔,xxbos i 'm stepping away from paying attention to politics for a few days / weeks after recent announcement about the xxmaj supreme xxmaj court , until i can think about it without the desperation / rage / fear / tears welling up sensation that i feel when i think about things right now . xxmaj sometimes you have to step back for a while when you really care , in order to preserve your xxunk . xxmaj we 're in this for the long haul , and positive things are happening too . xxmaj do n't let the bad stuff take you down with it .,xxbos xxmaj no . xxmaj it automatically comes from neckbeards because it 's typical whiny bollocks that does n't translate into real life . \n",
       "  xxmaj nice gender stereotyping , and heteronormative statements . xxmaj but coming from the guy who has an issue with feminists , i 'm not surprised . \n",
       "  xxmaj is that supposed to insult me ? xxmaj think what you want . i do n't care .\n",
       "y: CategoryList\n",
       "intj,intp,entp,infj,intj\n",
       "Path: model;\n",
       "\n",
       "Valid: LabelList (45969 items)\n",
       "x: TextList\n",
       "xxbos xxmaj yes , i see them every week and i just got my xxmaj real xxmaj estate xxmaj license to work with my xxmaj mexican mum . xxmaj we 're pretty close . \n",
       "  i cooked for my boyfriend on our second date he he lied about liking cilantro . i 've never been properly cheated on but this was the closest thing . xxmaj we 've been working through this for four years .,xxbos xxmaj fellow enfjs ! xxmaj what do you find most frustrating about other types ? \n",
       "  xxmaj for example , i find a lot of non - xxmaj fe people to occasionally be socially unaware and / or inconsiderate . i still love 'em , obviously , but xxup grr . \n",
       "  xxmaj what 's yours ? xxmaj vent !,xxbos xxmaj my grieving process differs for each situation . xxmaj this is my grieving process of my current situation i 'm dealing with now ... \n",
       " \n",
       "  xxmaj shock mode , unable to process what 's going on . xxmaj is this really happening ? xxmaj why am i not crying ? xxmaj probably what you call detachment mode in the beginning . xxmaj ca n't really seem to talk to most people about it except for my best friend . \n",
       "  xxmaj grieving ... xxmaj when the emotions hit hard . xxmaj sometimes crying is involved . \n",
       "  xxmaj unhealthy coping mechanism for example alcohol . \n",
       "  xxmaj acceptance of what happened and then i find every solution or way to repair the situation . xxmaj this is also the time i 'm seeking for answers . xxmaj during this time i am also doing stuff to self improve . \n",
       "  i start feeling better and feel like i 'm healing . \n",
       "  xxmaj but wait , it did n't get fixed correctly so then i 'm dealing with failure now . \n",
       "  xxmaj then denial ... xxmaj is this really going to work or am i just wasting my time fixing something that 's irreparable ? \n",
       "  xxmaj unhealthy coping mechanism with alcohol again to deal with all this . \n",
       "  xxmaj repeat steps 2 - 8 for awhile . \n",
       "  xxmaj then finally reality hits me , got ta accept my truth and move on for good . xxmaj some grieving , support from others , coping mechanism are all involved for me to be able to move on easier . \n",
       " \n",
       "  xxmaj luckily not much anger involved in this situation . xxmaj just a lot of sorrow . i used to self detach from every situation when i was younger , that was my go to number 1 thing to do , but it seemed like i was running away from my problems instead of facing them . xxmaj so for this situation i 'm not using detachment as much .,xxbos xxmaj it has been about 3 years for me to figure out my personality type from the inaccuracies of taking the mbti test multiple times . i am unsure whether my personality is correct but i kept testing to make sure of my results . i got xxup istj many times now . i had kept notes of my results since those years and saw i had xxup enfp before . i 'm 19 which feels young to me to be considered knowledgeable since i know there s a lot to learn even during those past years . \n",
       "  xxmaj well , i was considering whether i am an xxup enfp or xxup istj after i thought maybe i should read the \" xxmaj extrovert \" side descriptions . xxmaj after i did , i felt something familiar . xxmaj it must be because of the functions . xxup istj having xxmaj si - xxmaj te - xxmaj fi - xxmaj ne and xxup enfp having xxmaj ne - xxmaj fi - xxmaj te - xxmaj si , i hope i 'm not mistaken of these functions but i 'm sure it should be right . i had read that both of these personality are more ambivert than some others too so there should be a reason for that . \n",
       "  xxmaj from my experience during my pre - teen years i was very spontaneous but that s with my closest friends ( 2 of them ) and they thought i was weird in a good way . ( i 'd be so comfortable that i 'd be running and jumping ) i can be silly and weird . i only was like this with my church friends mostly , because for school , i wanted to focus on the teacher and listen ( at least tried to ) . i did n't bother much with interacting with other students since i was occupied with my work , but i did like listening to others ' conversations . xxmaj it makes me want to join in too but i just did n't have time for that . xxmaj so i 'm pretty much very focused on my work but i have a fun side to express too . i can get really creative with words , puns and seems like to others its bad / good ? i was asked before \" how did you come up with these ? \" ... xxmaj but it really just comes to my mind . xxmaj like i feel like i 'm constantly thinking and when my mind gets bored or when i find a really good joke , i 'll say it .,xxbos xxmaj do n't waste time on the race to be xxmaj mr or xxmaj miss xxmaj popular . xxmaj friendships is about quality , not quantity . xxmaj do n't succumb to peer pressure to become somebody you 're not , or do \n",
       "  dangerous and illegal things \n",
       "  xxmaj unless it breaks rules , do what makes you happy and enjoy your youth before you become an adult . xxmaj of course , you should try your best to get good grades in school , but set aside time for leisure as well .\n",
       "y: CategoryList\n",
       "intj,enfj,intp,istj,istp\n",
       "Path: model;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(60004, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(60004, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1150, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1150, 1150, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1150, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=16, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fab1dc847b8>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('model'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): Embedding(60004, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(60004, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=16, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=None)\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): Embedding(60004, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(60004, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=16, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load(\"save1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.881740</td>\n",
       "      <td>1.803093</td>\n",
       "      <td>0.419326</td>\n",
       "      <td>1:07:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, slice(2e-4/100, 2e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
